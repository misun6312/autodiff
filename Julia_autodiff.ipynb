{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PBupsModel with Algorithmic Differentiation in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: New definition \n",
      "    write(Base.IO, ForwardDiff.Partials) at /Users/msyoon/.julia/v0.4/ForwardDiff/src/partials.jl:57\n",
      "is ambiguous with: \n",
      "    write(Base.Base64.Base64EncodePipe, AbstractArray{UInt8, 1}) at base64.jl:89.\n",
      "To fix, define \n",
      "    write(Base.Base64.Base64EncodePipe, ForwardDiff.Partials{N<:Any, UInt8})\n",
      "before the new definition.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "convert (generic function with 647 methods)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages..\n",
    "import ForwardDiff\n",
    "using ForwardDiff\n",
    "using DiffBase\n",
    "using PyPlot\n",
    "import Base.convert\n",
    "import Optim\n",
    "using Optim\n",
    "\n",
    "# === Upgrading from ForwardDiff v0.1 to v0.2\n",
    "# instead of ForwardDiff.GradientNumber and ForwardDiff.HessianNumber, \n",
    "# we will use ForwardDiff.Dual\n",
    "\n",
    "convert(::Type{Float64}, x::ForwardDiff.Dual) = Float64(x.value)\n",
    "function convert(::Array{Float64}, x::Array{ForwardDiff.Dual}) \n",
    "    y = zeros(size(x)); \n",
    "    for i in 1:prod(size(x)) \n",
    "        y[i] = convert(Float64, x[i]) \n",
    "    end\n",
    "    return y\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isless (generic function with 32 methods)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immutable NumericPair{X,Y} <: Number\n",
    "  x::X\n",
    "  y::Y\n",
    "end\n",
    "Base.isless(a::NumericPair, b::NumericPair) = (a.x<b.x) || (a.x==b.x && a.y<b.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how well a particular set of parameter values $\\theta$ fits the behavioral data, we compute the probability of oberving the data given the model.\n",
    "\n",
    "For each trial $i$, we will compute the likelihood of seeing the data under the model assuming that trials are independent. \n",
    "\n",
    "$P(D|\\theta) = \\prod_{i}P(d_i|t_{i,R},t_{i,L},\\theta)$\n",
    "\n",
    "$t_{i,R},t_{i,L}$ : the right and left click times on trial $i$\n",
    "\n",
    "$d_i$ : the subject's decision on trial $i$\n",
    "\n",
    "The best-fit parameter values are the parameters $\\theta$ that maximize the likelihood (Maximum likelihood values)\n",
    "\n",
    "To help maximize the likelihood(or log likelihood), we will compute the derivative $\\partial P(d_i|t_{i,R},t_{i,L},\\theta) / \\partial\\theta$ for each of the parameters in the set $\\theta$.\n",
    "\n",
    "After we get these gradients of 9 model parameters, we will apply them for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{ASCIIString,Any} with 5 entries:\n",
       "  \"ratname\"      => \"B069\"\n",
       "  \"daterange\"    => 1x2 Array{Any,2}:…\n",
       "  \"rawdata\"      => Dict{ASCIIString,Any}(\"is_probe\"=>1x64537 Array{Any,2}:…\n",
       "  \"avgdata\"      => Dict{ASCIIString,Any}(\"is_probe\"=>1x64537 Array{Bool,2}:…\n",
       "  \"total_trials\" => 64537.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MAT\n",
    "# ratdata = matread(\"testdata.mat\")\n",
    "ratdata2 = matread(\"chrono_B069_rawdata.mat\")\n",
    "# ratdata2 = matread(\"ai3space_nolsr_rawdata.mat\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{ASCIIString,Any} with 5 entries:\n",
       "  \"ratname\"      => \"B069\"\n",
       "  \"daterange\"    => 1x2 Array{Any,2}:…\n",
       "  \"rawdata\"      => Dict{ASCIIString,Any}(\"is_probe\"=>1x64537 Array{Any,2}:…\n",
       "  \"avgdata\"      => Dict{ASCIIString,Any}(\"is_probe\"=>1x64537 Array{Bool,2}:…\n",
       "  \"total_trials\" => 64537.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratdata = ratdata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Float64(ratdata2[\"rawdata\"][\"leftbups\"][3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: maxT not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: maxT not defined",
      ""
     ]
    }
   ],
   "source": [
    "ratdata[\"rawdata\"][\"leftbups\"][1]\n",
    "Nsteps = Int(cld(maxT,dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0,0.001135000000000004,0.011165000000000001,0.01892,0.10638,0.20342,0.32964499999999997,0.33775999999999995],[0.0,0.19235,0.34360999999999997],0.35095899999999747,-1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trialdata(rawdata, trial::Int)\n",
    "    if rawdata[\"pokedR\"][trial] > 0\n",
    "        rat_choice = 1;  # \"R\"\n",
    "    else\n",
    "        rat_choice = -1; # \"L\"\n",
    "    end;\n",
    "    \n",
    "    if typeof(rawdata[\"rightbups\"][trial]) <: Array\n",
    "        rvec = vec(rawdata[\"rightbups\"][trial])::Array{Float64,1};\n",
    "    else\n",
    "        rvec = Float64[rawdata[\"rightbups\"][trial]] # bug fixed for single pulse\n",
    "    end\n",
    "    if typeof(rawdata[\"leftbups\"][trial]) <: Array\n",
    "        lvec = vec(rawdata[\"leftbups\"][trial])::Array{Float64,1};\n",
    "    else\n",
    "        lvec = Float64[rawdata[\"leftbups\"][trial]] # bug fixed for single pulse\n",
    "    end\n",
    "    \n",
    "    return rvec, lvec, \n",
    "    rawdata[\"T\"][trial]::Float64, rat_choice\n",
    "end\n",
    "\n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000061 seconds (165 allocations: 42.448 KB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,0.001135000000000004,0.011165000000000001,0.01892,0.10638,0.20342,0.32964499999999997,0.33775999999999995],[0.0,0.19235,0.34360999999999997],0.35095899999999747,-1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 0.0     \n",
       " 0.001135\n",
       " 0.011165\n",
       " 0.01892 \n",
       " 0.10638 \n",
       " 0.20342 \n",
       " 0.329645\n",
       " 0.33776 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RightClickTimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin_centers = make_bins(B, dx, binN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function bin_centers = make_bins(B, dx, binN)\n",
    "\n",
    "Makes a series of points that will indicate bin centers. The first and\n",
    "last points will indicate sticky bins. No \"bin edges\" are made-- the edge\n",
    "between two bins is always implicity at the halfway point between their\n",
    "corresponding centers. The center bin is always at x=0; bin spacing\n",
    "(except for last and first bins) is always dx; and the position\n",
    "of the first and last bins is chosen so that |B| lies exactly at the\n",
    "midpoint between 1st (sticky) and 2nd (first real) bins, as well as\n",
    "exactly at the midpoint between last but one (last real) and last\n",
    "(sticky) bins.\n",
    "\n",
    "Playing nice with ForwardDiff means that the *number* of bins must be predetermined.\n",
    "So this function will not actually set the number of bins; what it'll do is determine their\n",
    "locations. To accomplish this separation, the function uses as a third parameter binN,\n",
    "which should be equal to the number of bins with bin centers > 0, as follows: \n",
    "   binN = ceil(B/dx)\n",
    "and then the total number of bins will be 2*binN+1, with the center one always corresponding\n",
    "to position zero. Use non-differentiable types for B and dx for this to work.\n",
    "\"\"\"\n",
    "function make_bins{T}(bins::Vector{T}, B, dx::T, binN)\n",
    "    cnt = 1\n",
    "    for i=-binN:binN\n",
    "        bins[cnt] = i*dx\n",
    "        cnt = cnt+1\n",
    "    end\n",
    "    \n",
    "    if binN*dx == B\n",
    "        bins[end] = B + dx\n",
    "        bins[1] = -B - dx\n",
    "    else\n",
    "        bins[end] = 2*B - (binN-1)*dx\n",
    "        bins[1] = -2*B + (binN-1)*dx\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.039068 seconds (57.89 k allocations: 2.331 MB)\n",
      "17.0 35\n"
     ]
    }
   ],
   "source": [
    "binN = ceil(4.1/0.25)\n",
    "bins = zeros(typeof(binN), Int(binN*2+1))\n",
    "@time make_bins(bins,4.1,0.25,binN)\n",
    "bins\n",
    "bin_centers = bins\n",
    "println(binN,\" \",length(bin_centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000008 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67-element Array{Float64,1}:\n",
       " -8.2 \n",
       " -8.0 \n",
       " -7.75\n",
       " -7.5 \n",
       " -7.25\n",
       " -7.0 \n",
       " -6.75\n",
       " -6.5 \n",
       " -6.25\n",
       " -6.0 \n",
       " -5.75\n",
       " -5.5 \n",
       " -5.25\n",
       "  ⋮   \n",
       "  5.5 \n",
       "  5.75\n",
       "  6.0 \n",
       "  6.25\n",
       "  6.5 \n",
       "  6.75\n",
       "  7.0 \n",
       "  7.25\n",
       "  7.5 \n",
       "  7.75\n",
       "  8.0 \n",
       "  8.2 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binN = ceil(8.1/0.25)\n",
    "bins = zeros(typeof(binN), Int(binN*2+1))\n",
    "@time make_bins(bins,8.1,0.25,binN)\n",
    "bins\n",
    "bin_centers = bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global variables \n",
    "const epsilon = 10.0^(-10);\n",
    "const dx = 0.25;\n",
    "const dt = 0.02;\n",
    "const total_rate = 40; #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "a : decision variable, memory accumulator\n",
    "\n",
    "$$ da =\n",
    "  \\begin{cases}\n",
    "    0       & \\quad \\text{if, } |a| \\geq B \\\\\n",
    "    \\sigma_adW + (\\delta_{t,t_R} \\cdot \\eta C(t) - \\delta_{t,t_L} \\cdot \\eta C(t))dt + \\lambda adt  & \\quad \\text{otherwise, }\\\\\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "The impact of each click (C) is affected by sensory adaptation that depends on clicks from both right and left sides:\n",
    "\n",
    "$$ \n",
    "\\frac{\\mathrm d C}{\\mathrm d t} = \\frac{1-C}{\\tau_\\phi} + (1-\\phi)C(\\delta_{t,t_R}+\\delta_{t,t_L}) \n",
    "$$\n",
    "\n",
    "\n",
    "sigma2_a ($\\sigma_a^2$) : a diffusion constant, parameterizing noise in a.\n",
    "\n",
    "sigma2_s ($\\sigma_s^2$) : parameterizing noise when adding evidence from a right or left pulse. (incoming sensory evidence)\n",
    "\n",
    "sigma2_i ($\\sigma_i^2$) : initial condition for the dynamical equation at $t=0$\n",
    "\n",
    "lam ($\\lambda$) : consistent drift in the memory a ($\\lambda<0$ : leaky or forgetful case, $\\lambda>0$ : unstable or impulsive case)\n",
    "\n",
    "B : decision bound\n",
    "\n",
    "bias : bias parameter determines the position of the threshold in a (which a Rightward decision is made)\n",
    "\n",
    "phi ($\\phi$) : parameterize sensory adaptation (by defining the dynamics of C ($\\phi>1$ : Facilitation, $\\phi<1$ : Depression, $\\phi=1$ : absense of sensory adaptation)\n",
    "\n",
    "tau_phi ($\\tau_\\phi$) :\n",
    "\n",
    "lapse : The lapse rate parameterizes the probability of making a random response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "sigma = params[1];\n",
    "lam   = params[2];\n",
    "c     = params[3];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F = Fmatrix([sigma, lambda, c], bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fmatrix (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "function F = Fmatrix([sigma, lambda, c], bin_centers)\n",
    "\n",
    "Uses globals\n",
    "    dt\n",
    "    dx\n",
    "    epsilon       (=10.0^-10)\n",
    "\n",
    "Returns a square Markov matrix of transition probabilities. \n",
    "Plays nice with ForwardDiff-- that is why bin_centers is a global vector (so that the rem\n",
    "operations that go into defining the bins, which ForwardDiff doesn't know how to deal with,\n",
    "stay outside of this differentiable function)\n",
    "\n",
    "sigma  should be in (accumulator units) per (second^(1/2))\n",
    "lambda should be in s^-1\n",
    "c      should be in accumulator units per second\n",
    "bin_centers should be a vector of the centers of all the bins. Edges will be at midpoints\n",
    "       between the centers, and the first and last bin will be sticky.\n",
    "\n",
    "dx is not used inside Fmatrix, because bin_centers specifies all we need to know.\n",
    "dt *is* used inside Fmatrix, to convert sigma, lambda, and c into timestep units\n",
    "\"\"\"\n",
    "function Fmatrix{T}(F::AbstractArray{T,2},params::Vector, bin_centers)\n",
    "    sigma2 = params[1];\n",
    "    lam   = params[2];\n",
    "    c     = params[3];\n",
    "\n",
    "    sigma2_sbin = convert(Float64, sigma2)\n",
    "\n",
    "    if dx > epsilon && sigma2_sbin >= epsilon\n",
    "        n_sbins = max(70, ceil(10*sqrt(sigma2_sbin)/dx))\n",
    "    else\n",
    "        n_sbins = 70\n",
    "    end\n",
    "        \n",
    "    F[1,1] = 1;\n",
    "    F[end,end] = 1;\n",
    "\n",
    "    if sigma2_sbin <= 0\n",
    "        sbin_length = 1;\n",
    "        base_sbins = 0;\n",
    "        ps = 0;\n",
    "    else\n",
    "        swidth = 5*sqrt(sigma2_sbin)\n",
    "        sbinsize = swidth/n_sbins;#sbins[2] - sbins[1]\n",
    "        base_sbins    = collect(-swidth:sbinsize:swidth)\n",
    "\n",
    "        ps       = exp(-base_sbins.^2/(2*sigma2))\n",
    "        ps       = ps/sum(ps);\n",
    "\n",
    "        sbin_length = length(base_sbins)\n",
    "    end    \n",
    "    \n",
    "    binN = length(bin_centers)\n",
    "\n",
    "    mu = 0.\n",
    "    for j in 2:binN-1\n",
    "        if abs(lam) < epsilon \n",
    "            mu = bin_centers[j] + c*dt#(exp(lam*dt))\n",
    "        else\n",
    "            mu = (bin_centers[j] + c/lam)*exp(lam*dt) - c/lam\n",
    "        end\n",
    "\n",
    "        for k in 1:sbin_length\n",
    "            sbin = mu + base_sbins[k]#(k-1)*sbinsize + mu - swidth\n",
    "\n",
    "            if sbin <= bin_centers[1] #(bin_centers[1] + bin_centers[2])/2\n",
    "                F[1,j] = F[1,j] + ps[k]\n",
    "            elseif bin_centers[end] <= sbin#(bin_centers[end]+bin_centers[end-1])/2 <= sbins[k]\n",
    "                F[end,j] = F[end,j] + ps[k]\n",
    "            else # more condition\n",
    "                if (sbin > bin_centers[1] && sbin < bin_centers[2])\n",
    "                    lp = 1; hp = 2;\n",
    "                elseif (sbin > bin_centers[end-1] && sbin < bin_centers[end])\n",
    "                    lp = binN-1; hp = binN;\n",
    "                else\n",
    "                    lp = floor(Int,((sbin-bin_centers[2])/dx)) + 2#find(bin_centers .<= sbins[k])[end]\n",
    "                    hp = ceil(Int,((sbin-bin_centers[2])/dx)) + 2#lp+1#Int(ceil((sbins[k]-bin_centers[2])/dx) + 1);\n",
    "                end\n",
    "\n",
    "                # if lp < 1\n",
    "                #     lp = 1;\n",
    "                # end\n",
    "                # if hp > binN-1\n",
    "                #     hp = binN-1;\n",
    "                # end\n",
    "\n",
    "                if lp == hp\n",
    "                    F[lp,j] = F[lp,j] + ps[k]\n",
    "                else\n",
    "                    F[hp,j] = F[hp,j] + ps[k]*(sbin - bin_centers[lp])/(bin_centers[hp] - bin_centers[lp])\n",
    "                    F[lp,j] = F[lp,j] + ps[k]*(bin_centers[hp] - sbin)/(bin_centers[hp] - bin_centers[lp])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # F[:,1] = 0; F[:,end] = 0; F[1,1] = 1; F[end,end] = 1;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.366498 seconds (191.80 k allocations: 6.324 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67x67 Array{Float64,2}:\n",
       " 1.0  0.41182      0.218907     0.0917964    …  0.0          0.0          0.0\n",
       " 0.0  0.197142     0.172131     0.112014        0.0          0.0          0.0\n",
       " 0.0  0.187228     0.217923     0.187228        0.0          0.0          0.0\n",
       " 0.0  0.119939     0.187228     0.217923        0.0          0.0          0.0\n",
       " 0.0  0.0571377    0.119939     0.187228        0.0          0.0          0.0\n",
       " 0.0  0.0202246    0.0571377    0.119939     …  0.0          0.0          0.0\n",
       " 0.0  0.00531176   0.0202246    0.0571377       0.0          0.0          0.0\n",
       " 0.0  0.00103206   0.00531176   0.0202246       0.0          0.0          0.0\n",
       " 0.0  0.000148294  0.00103206   0.00531176      0.0          0.0          0.0\n",
       " 0.0  1.59548e-5   0.000148294  0.00103206      0.0          0.0          0.0\n",
       " 0.0  1.11105e-6   1.59548e-5   0.000148294  …  0.0          0.0          0.0\n",
       " 0.0  0.0          1.11105e-6   1.59548e-5      0.0          0.0          0.0\n",
       " 0.0  0.0          0.0          1.11105e-6      0.0          0.0          0.0\n",
       " ⋮                                           ⋱               ⋮               \n",
       " 0.0  0.0          0.0          0.0          …  1.11105e-6   0.0          0.0\n",
       " 0.0  0.0          0.0          0.0             1.59548e-5   1.11105e-6   0.0\n",
       " 0.0  0.0          0.0          0.0             0.000148294  1.59548e-5   0.0\n",
       " 0.0  0.0          0.0          0.0             0.00103206   0.000148294  0.0\n",
       " 0.0  0.0          0.0          0.0             0.00531176   0.00103206   0.0\n",
       " 0.0  0.0          0.0          0.0          …  0.0202246    0.00531176   0.0\n",
       " 0.0  0.0          0.0          0.0             0.0571377    0.0202246    0.0\n",
       " 0.0  0.0          0.0          0.0             0.119939     0.0571377    0.0\n",
       " 0.0  0.0          0.0          0.0             0.187228     0.119939     0.0\n",
       " 0.0  0.0          0.0          0.0             0.217923     0.187228     0.0\n",
       " 0.0  0.0          0.0          0.0          …  0.172131     0.197142     0.0\n",
       " 0.0  0.0          0.0          0.0             0.218907     0.41182      1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = zeros(typeof(0.2),length(bin_centers),length(bin_centers))\n",
    "@time Fmatrix(F,[0.2, 0, 0.0],bin_centers) # Fi\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004142 seconds (78.30 k allocations: 1.202 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67x67 Array{Float64,2}:\n",
       " 1.0  0.464534    0.368213    0.27785    …  0.0         0.0         0.0\n",
       " 0.0  0.0901428   0.0863713   0.0807973     0.0         0.0         0.0\n",
       " 0.0  0.0952597   0.0999224   0.0957109     0.0         0.0         0.0\n",
       " 0.0  0.0877379   0.0952181   0.0999795     0.0         0.0         0.0\n",
       " 0.0  0.0739267   0.0878095   0.0951766     0.0         0.0         0.0\n",
       " 0.0  0.0601908   0.0739127   0.0878812  …  0.0         0.0         0.0\n",
       " 0.0  0.0447953   0.0602548   0.0738987     0.0         0.0         0.0\n",
       " 0.0  0.0322435   0.0447976   0.0603187     0.0         0.0         0.0\n",
       " 0.0  0.0211932   0.0322857   0.0448        0.0         0.0         0.0\n",
       " 0.0  0.0134871   0.0211994   0.032328      0.0         0.0         0.0\n",
       " 0.0  0.00782868  0.0135081   0.0212055  …  0.0         0.0         0.0\n",
       " 0.0  0.00440511  0.00783279  0.0135292     0.0         0.0         0.0\n",
       " 0.0  0.00225787  0.00441308  0.0078369     0.0         0.0         0.0\n",
       " ⋮                                       ⋱              ⋮              \n",
       " 0.0  0.0         0.0         0.0        …  0.00776708  0.00427765  0.0\n",
       " 0.0  0.0         0.0         0.0           0.0131718   0.00776297  0.0\n",
       " 0.0  0.0         0.0         0.0           0.0211008   0.0131508   0.0\n",
       " 0.0  0.0         0.0         0.0           0.0316098   0.0210946   0.0\n",
       " 0.0  0.0         0.0         0.0           0.0447599   0.0315676   0.0\n",
       " 0.0  0.0         0.0         0.0        …  0.0592314   0.0447575   0.0\n",
       " 0.0  0.0         0.0         0.0           0.074137    0.0591674   0.0\n",
       " 0.0  0.0         0.0         0.0           0.0866636   0.074151    0.0\n",
       " 0.0  0.0         0.0         0.0           0.095883    0.086592    0.0\n",
       " 0.0  0.0         0.0         0.0           0.0990097   0.0959245   0.0\n",
       " 0.0  0.0         0.0         0.0        …  0.0867834   0.0894404   0.0\n",
       " 0.0  0.0         0.0         0.0           0.37142     0.467942    1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = zeros(typeof(params[1]),length(bin_centers),length(bin_centers))\n",
    "@time Fmatrix(F,params,bin_centers)\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logProbRight \n",
    "### (params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int)\n",
    "\n",
    "* params = [sigma_a, sigma_s, sigma_i, lambda, B, bias, phi, tau_phi, lapse]\n",
    "* RightClickTimes vector with elements indicating times of right clicks\n",
    "* LeftClickTimes vector with elements indicating times of left clicks\n",
    "* Nsteps number of timesteps to simulate \n",
    "\n",
    "a (column vector representing distribution of values of accumulator a)\n",
    "\n",
    "a_trace (length(bin_centers)-by-Nsteps+1), a trace of the distribution of a as \n",
    "    a function of time\n",
    "    \n",
    "c_trace (row vector Nsteps+1 long, effective value of c as \n",
    "    a function of time after adaptation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logLike (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "version with inter-click interval(ici) for c_eff_net / c_eff_tot (followed the matlab code) \n",
    "(which was using dt for c_eff)\n",
    "\n",
    "function logProbRight(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int)\n",
    "\n",
    "    Nsteps            number of timesteps to simulate\n",
    "    RightClickTimes   vector with elements indicating times of right clicks\n",
    "    LeftClickTimes    vector with elements indicating times of left clicks\n",
    "\n",
    "    a      (column vector representing distribution of values of accumulator a)\n",
    "\n",
    "    a_trace (length(bin_centers)-by-Nsteps+1), a trace of the distribution of a as \n",
    "            a function of time\n",
    "    c_trace (row vector Nsteps+1 long, effective value of c as \n",
    "            a function of time after adaptation)\n",
    "\n",
    "Takes params\n",
    "    sigma_a = params[1]; sigma_s = params[2]; sigma_i = params[3]; \n",
    "    lambda = params[4]; B = params[5]; bias = params[6]; \n",
    "    phi = params[7]; tau_phi = params[8]; lapse = params[9]\n",
    "\n",
    "Returns the log of the probability that the agent chose Right. \n",
    "\"\"\"\n",
    "\n",
    "function logProbRight(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int)\n",
    "    sigma_a = params[1]; sigma_s = params[2]; sigma_i = params[3];\n",
    "    lambda = params[4]; B = params[5]; bias = params[6];\n",
    "    phi = params[7]; tau_phi = params[8]; lapse = params[9]\n",
    "\n",
    "    if isempty(RightClickTimes) RightClickTimes = zeros(0) end;\n",
    "    if isempty(LeftClickTimes ) LeftClickTimes  = zeros(0) end;\n",
    "\n",
    "    NClicks = zeros(Int, Nsteps);\n",
    "    Lhere  = zeros(Int, length(LeftClickTimes));\n",
    "    Rhere = zeros(Int, length(RightClickTimes));\n",
    "\n",
    "    for i in 1:length(LeftClickTimes)\n",
    "        Lhere[i] = ceil((LeftClickTimes[i]+epsilon)/dt)\n",
    "    end\n",
    "    for i in 1:length(RightClickTimes)\n",
    "        Rhere[i] = ceil((RightClickTimes[i]+epsilon)/dt)\n",
    "    end\n",
    "\n",
    "    for i in Lhere\n",
    "        NClicks[Int(i)] = NClicks[Int(i)]  + 1\n",
    "    end\n",
    "    for i in Rhere\n",
    "        NClicks[Int(i)] = NClicks[Int(i)]  + 1\n",
    "    end\n",
    "\n",
    "    # === Upgrading from ForwardDiff v0.1 to v0.2\n",
    "    # instead of using convert we can use floor(Int, ForwardDiff.Dual) and\n",
    "    # ceil(Int, ForwardDiff.Dual)\n",
    "\n",
    "    binN = ceil(Int, B/dx)#Int(ceil(my_B/dx))\n",
    "    binBias = floor(Int, bias/dx) + binN+1\n",
    "    binBias_hp = ceil(Int, bias/dx) + binN+1\n",
    "\n",
    "    if binBias<1 binBias = 1; end\n",
    "    if binBias>binN*2+1 binBias = binN*2+1; end\n",
    "\n",
    "    if binBias_hp<1 binBias_hp = 1; end\n",
    "    if binBias_hp>binN*2+1 binBias_hp = binN*2+1; end\n",
    "    \n",
    "    bin_centers = zeros(typeof(dx), binN*2+1)\n",
    "    make_bins(bin_centers, B, dx, binN)\n",
    "\n",
    "    a0 = zeros(typeof(sigma_a),length(bin_centers))\n",
    "    a0[binN+1] = 1-lapse; a0[1] = lapse/2; a0[end] = lapse/2;\n",
    "\n",
    "    temp_l = [NumericPair(LeftClickTimes[i],-1) for i=1:length(LeftClickTimes)]\n",
    "    temp_r = [NumericPair(RightClickTimes[i],1) for i=1:length(RightClickTimes)]\n",
    "    allbups = sort!([temp_l; temp_r])\n",
    "    \n",
    "    if phi == 1\n",
    "      c_eff = 1.\n",
    "    else\n",
    "      c_eff = 0.\n",
    "    end\n",
    "    \n",
    "    cnt = 0\n",
    "\n",
    "    Fi = zeros(typeof(sigma_i),length(bin_centers),length(bin_centers))\n",
    "    Fmatrix(Fi,[sigma_i, 0, 0.0], bin_centers)\n",
    "\n",
    "    a = Fi*a0;\n",
    "\n",
    "    F0 = zeros(typeof(sigma_a),length(bin_centers),length(bin_centers))\n",
    "    Fmatrix(F0,[sigma_a*dt, lambda, 0.0], bin_centers)\n",
    "    for i in 2:Nsteps\n",
    "        c_eff_tot = 0.\n",
    "        c_eff_net = 0.\n",
    "        if NClicks[i-1]==0\n",
    "            c_eff_tot = 0.\n",
    "            c_eff_net = 0.\n",
    "            a = F0*a\n",
    "        else\n",
    "            for j in 1:NClicks[i-1]\n",
    "                if cnt != 0 || j != 1\n",
    "                    ici = allbups[cnt+j].x - allbups[cnt+j-1].x\n",
    "                    c_eff = 1 + (c_eff*phi - 1)*exp(-ici/tau_phi)\n",
    "                    c_eff_tot = c_eff_tot + c_eff\n",
    "                    c_eff_net = c_eff_net + c_eff*allbups[cnt+j].y\n",
    "                elseif cnt==0 && j==1\n",
    "                    ici = 0.\n",
    "                    c_eff = 1 + (c_eff*phi - 1)*exp(-ici/tau_phi)# bug fixed.   <--- this depends on first 0. 0.\n",
    "                    # c_eff = 1 #(when there is no first 0.  )\n",
    "                    c_eff_tot = c_eff_tot + c_eff\n",
    "                    c_eff_net = c_eff_net + c_eff*allbups[cnt+j].y\n",
    "                end\n",
    "                if j == NClicks[i-1]\n",
    "                    cnt = cnt+j\n",
    "                end\n",
    "            end\n",
    "\n",
    "            net_sigma = sigma_a*dt + (sigma_s*c_eff_tot)/total_rate\n",
    "            F = zeros(typeof(net_sigma),length(bin_centers),length(bin_centers))\n",
    "            Fmatrix(F,[net_sigma, lambda, c_eff_net/dt], bin_centers)\n",
    "            a = F*a\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if binBias == binBias_hp\n",
    "      pright = sum(a[binBias+1:end])+a[binBias]/2\n",
    "    else\n",
    "      pright = sum(a[binBias+2:end]) +\n",
    "      a[binBias]*((bin_centers[binBias+1] - bias)/dx/2) +\n",
    "      a[binBias+1]*(0.5 + (bin_centers[binBias+1] - bias)/dx/2)\n",
    "    end\n",
    "\n",
    "    if pright-1 < epsilon && pright > 1\n",
    "        pright = 1\n",
    "    end\n",
    "    if pright < epsilon && pright > 0 \n",
    "        pright = 0\n",
    "    end\n",
    "\n",
    "    \n",
    "    return log(pright)\n",
    "end\n",
    "\n",
    "\n",
    "function logLike(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int)\n",
    "    if rat_choice > 0\n",
    "        # println(\"Right\")\n",
    "        return logProbRight(params, RightClickTimes, LeftClickTimes, Nsteps)\n",
    "    elseif rat_choice < 0\n",
    "        # println(\"Left\")\n",
    "        return log(1 - exp(logProbRight(params, RightClickTimes, LeftClickTimes, Nsteps)))\n",
    "    else\n",
    "        error(\"Rat did what?? It was neither R nor L\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single_trial\n",
    "### (params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single_trial (generic function with 2 methods)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "function (LL, LLgrad) = \n",
    "    single_trial(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int)\n",
    "\n",
    "Computes the log likelihood according to Bing's model, and returns log likelihood, gradient\n",
    "\n",
    "params is a vector whose elements, in order, are\n",
    "    sigma_a    square root of accumulator variance per unit time sqrt(click units^2 per second)\n",
    "    sigma_s    standard deviation introduced with each click (will get scaled by click adaptation)\n",
    "    sigma_i    square root of initial accumulator variance sqrt(click units^2)\n",
    "    lambda     1/accumulator time constant (sec^-1). Positive means unstable, neg means stable\n",
    "    B          sticky bound height (click units)\n",
    "    bias       where the decision boundary lies (click units)\n",
    "    phi        click adaptation/facilitation multiplication parameter\n",
    "    tau_phi    time constant for recovery from click adaptation (sec)\n",
    "    lapse      2*lapse fraction of trials are decided randomly\n",
    "\n",
    "rat_choice     should be either \"R\" or \"L\"\n",
    "\n",
    "\n",
    "RETURNS:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# === Upgrading from ForwardDiff v0.1 -> v0.2 -> v0.3\n",
    "# for Retrieving Lower-Order Results\n",
    "#     # old way\n",
    "#     answer, results = ForwardDiff.hessian(f, x, AllResults)\n",
    "#     v = ForwardDiff.value(results)\n",
    "#     g = ForwardDiff.gradient(results)\n",
    "#     h = ForwardDiff.hessian(results) # == answer\n",
    "\n",
    "#     # old v0.2 style\n",
    "#     out = HessianResult(x)\n",
    "#     ForwardDiff.hessian!(out, f, x)\n",
    "#     v = ForwardDiff.value(out)\n",
    "#     g = ForwardDiff.gradient(out)\n",
    "#     h = ForwardDiff.hessian(out)\n",
    "\n",
    "#     # current v0.3 style\n",
    "#     using DiffBase\n",
    "#     out = DiffBase.HessianResult(x)\n",
    "#     ForwardDiff.hessian!(out, f, x)\n",
    "#     v = DiffBase.value(out)\n",
    "#     g = DiffBase.gradient(out)\n",
    "#     h = DiffBase.hessian(out)\n",
    "\n",
    "\n",
    "function single_trial(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int, hess_mode=0::Int)\n",
    "    function llikey(params::Vector)\n",
    "        logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "    end\n",
    "\n",
    "    if hess_mode > 0\n",
    "        result =  DiffBase.HessianResult(params) \n",
    "        ForwardDiff.hessian!(result, llikey, params);\n",
    "    else\n",
    "        result =  DiffBase.GradientResult(params)\n",
    "        ForwardDiff.gradient!(result, llikey, params);\n",
    "    end\n",
    "\n",
    "    LL     = DiffBase.value(result)\n",
    "    LLgrad = DiffBase.gradient(result)\n",
    "    \n",
    "    if hess_mode > 0\n",
    "        LLhessian = DiffBase.hessian(result)\n",
    "    end\n",
    "   \n",
    "    if hess_mode > 0\n",
    "        return LL, LLgrad, LLhessian\n",
    "    else\n",
    "        return LL, LLgrad\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.067853 seconds (438.58 k allocations: 7.133 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.3370676666063943"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### =============== testing 1 ================= ####\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "lam = -0.5; B = 6.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], 1)\n",
    "Nsteps = Int(cld(maxT,dt))\n",
    "\n",
    "@time logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "\n",
    "### =========================================== #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0    \n",
       " 0.19235\n",
       " 0.34361"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeftClickTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.016094 seconds (369.90 k allocations: 5.812 MB, 19.94% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9-element Array{Float64,1}:\n",
       "  2.0277\n",
       "  1.174 \n",
       "  1.1142\n",
       " -0.6808\n",
       "  5.339 \n",
       "  0.7396\n",
       "  1.526 \n",
       "  0.5899\n",
       "  0.1689"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = [3.6936, 2.1375, 0.7552, 1.0569, 10.3493, 0.2394, 1.1123, 0.6047, 0.1301];\n",
    "X = [2.0277     1.1740    1.1142    -0.6808   5.3390    0.7396    1.5260    0.5899    0.1689]\n",
    "#X = [1.0  0.1  0.2  -0.5  6.1  0.1  0.3  0.1  0.1];\n",
    "\n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = \n",
    "trialdata(ratdata[\"rawdata\"], 1)\n",
    "Nsteps = Int(cld(maxT,dt))\n",
    "\n",
    "@time logLike(vec(X), RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "params = vec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.020784 seconds (327.99 k allocations: 28.171 MB, 14.83% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2.0692503809913823,[0.10146020263577106,0.031142826708387732,0.23150884407176742,0.20237251853355287,-0.0,0.4736473147030815,-2.726144808160129,1.7123865901824764,3.5608739897947106])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# first call for compiling\n",
    "@time LL, LLgrad = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: DiffBase not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: DiffBase not defined",
      "",
      " in single_trial at In[22]:55"
     ]
    }
   ],
   "source": [
    "### =============== testing 2 ================= ####\n",
    "@time LL, LLgrad, LLhess = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice, 1)\n",
    "println(LL)\n",
    "println(LLgrad)\n",
    "# println(LLhess)\n",
    "imshow(log(abs(LLhess)), interpolation=\"none\")\n",
    "### =========================================== ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LLgrad[5]==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LLhess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pkg.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Maximize LL over parameter space\n",
    "### Optimization with Optim.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"Optim\")\n",
    "\n",
    "# import Optim\n",
    "# using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SumLikey_hess (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SumLikey_LL(params::Vector, ratdata, ntrials::Int)\n",
    "    LL        = 0.\n",
    "        \n",
    "    for i in 1:ntrials\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LLi = logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "        LL        = LL + LLi;\n",
    "    end\n",
    "    \n",
    "    LL = -LL\n",
    "    return LL\n",
    "end\n",
    "\n",
    "function SumLikey(params::Vector, ratdata, ntrials::Int)\n",
    "    LL        = 0.\n",
    "    LLgrad    = zeros(Float64,length(params))\n",
    "    \n",
    "    for i in 1:ntrials\n",
    "        if rem(i,1000)==0\n",
    "            println(\"     sum_ll_all_trials: running trial \", i, \"/\", ntrials);\n",
    "        end\n",
    "\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LLi, LLgradi = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "        LL        = LL + LLi;\n",
    "        LLgrad    = LLgrad + LLgradi;\n",
    "        \n",
    "    end\n",
    "\n",
    "    LL = -LL\n",
    "    LLgrad = -LLgrad\n",
    "    return LL, LLgrad\n",
    "end\n",
    "\n",
    "\n",
    "function SumLikey_hess(params::Vector, ratdata, ntrials::Int)\n",
    "    LL        = 0.\n",
    "    LLhess    = zeros(Float64,length(params),length(params))\n",
    "    \n",
    "    for i in 1:ntrials\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LLi, LLgradi, LLhessi = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice, 1)\n",
    "        LL        = LL + LLi;\n",
    "        LLhess    = LLhess + LLhessi;\n",
    "    end\n",
    "\n",
    "    LL = -LL\n",
    "    return LL, LLhess\n",
    "end\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SumLikey_test (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SumLikey_test(params::Vector, ratdata, ntrials::Int)\n",
    "    LL        = 0.\n",
    "    LLgrad    = zeros(Float64,length(params))\n",
    "    LLgrads    = zeros(Float64,ntrials,length(params))\n",
    "    \n",
    "    for i in 1:ntrials\n",
    "        if rem(i,1000)==0\n",
    "            println(\"     sum_ll_all_trials: running trial \", i, \"/\", ntrials);\n",
    "        end\n",
    "\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LLi, LLgradi = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "        LL        = LL + LLi;\n",
    "        LLgrad    = LLgrad + LLgradi;\n",
    "        \n",
    "        LLgrads[i,:] = LLgradi;\n",
    "        \n",
    "    end\n",
    "\n",
    "    LL = -LL\n",
    "    LLgrad = -LLgrad\n",
    "    return LL, LLgrad, LLgrads\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3370676666063748"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [1.0  0.1  0.2  -0.5  6.1  0.1  0.3  0.1  0.1];\n",
    "# X = [2.0277     1.1740    1.1142    -0.6808   5.3390    0.7396    1.5260    0.5899    0.1689];\n",
    "LL, LLgrad, LLgrads = SumLikey_test(vec(X), ratdata, 1)\n",
    "\n",
    "LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = [1.0  0.1  0.2  -0.5  6.1  0.1  0.3  0.1  0.1];\n",
    "X = [2.0277     1.1740    1.1142    -0.6808   5.3390    0.7396    1.5260    0.5899    0.1689];\n",
    "LL, LLgrad, LLgrads = SumLikey_test(vec(X), ratdata, 9342)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_9p_jtom = [4 1 2 3 5 7 8 6 9]\n",
    "println(-LLgrad[idx_9p_jtom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_9p_jtom = [4 1 2 3 5 7 8 6 9];\n",
    "-LLgrad[idx_9p_jtom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function values_test(params::Vector, ratdata, ntrials::Int)\n",
    "    LL        = 0.\n",
    "    LLs       = zeros(Float64,ntrials)\n",
    "    LLgrad    = zeros(Float64,length(params))\n",
    "    LLgrads    = zeros(Float64,ntrials,length(params))\n",
    "    \n",
    "    for i in 1:ntrials\n",
    "#         println(i);\n",
    "        if rem(i,1000)==0\n",
    "            println(\"     sum_ll_all_trials: running trial \", i, \"/\", ntrials);\n",
    "        end\n",
    "\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LLi, LLgradi = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "        LL        = LL + LLi;\n",
    "        LLgrad    = LLgrad + LLgradi;\n",
    "        \n",
    "        LLs[i] = LLi;\n",
    "        LLgrads[i,:] = LLgradi;\n",
    "        \n",
    "    end\n",
    "\n",
    "    LL = -LL\n",
    "    LLgrad = -LLgrad\n",
    "    return LL, LLs, LLgrad, LLgrads\n",
    "end\n",
    "\n",
    "idx_9p_jtom = [4 1 2 3 5 7 8 6 9];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1775.2428041461042,[-2.33707,-0.0618188,-0.0528979,-2.84852,-0.0699918,-2.26443,-0.0512956,-0.0513216,-1.38283,-0.0577225  …  -0.0516494,-0.0513856,-2.76789,-0.454964,-0.0670277,-0.052299,-0.08573,-0.0803528,-0.061892,-2.8754],[-69.69235815137975,-16.674090441958178,-258.81900222646425,-10.419964376508453,-0.0,-134.8173131793887,312.2165802004942,-2672.3782337810135,-2501.6375128467803],\n",
       "3000x9 Array{Float64,2}:\n",
       "  0.375847      0.079608      0.916723     …  10.2667        4.63936 \n",
       " -0.0148792    -0.00351455   -0.0363425       -0.482546     -0.520128\n",
       " -0.0032281    -0.000749444  -0.0107699       -0.123299     -0.525377\n",
       "  0.161308      0.0351833     0.809886         6.8455        8.47898 \n",
       " -0.0163281    -0.00392919   -0.0932055       -0.69094      -0.515278\n",
       "  0.341942      0.0706047     1.13845      …   8.33189       4.23645 \n",
       " -1.3018e-5    -3.11553e-6   -2.32648e-5      -0.000360273  -0.526314\n",
       " -0.000123353  -2.65313e-5   -0.000208954     -0.00338755   -0.526299\n",
       "  0.139741      0.0314948     0.796376         6.86034       1.10342 \n",
       " -0.0109124    -0.00259516   -0.0219539       -0.394645     -0.522544\n",
       "  0.0820874     0.0164706     0.298486     …   2.20729       0.47024 \n",
       " -0.000525467  -0.00014337   -0.00119987      -0.0174664    -0.526223\n",
       " -0.0389006    -0.00951827   -0.255611        -1.38109      -0.459801\n",
       "  ⋮                                        ⋱                         \n",
       "  0.230699      0.0527941     1.31639         12.9614        2.43949 \n",
       "  0.105761      0.0229875     0.212821         3.06204       9.43148 \n",
       " -0.000962904  -0.0002513    -0.002947     …  -0.0295942    -0.526108\n",
       " -0.000302116  -7.82646e-5   -0.000924772     -0.0105067    -0.526262\n",
       "  0.27865       0.0776405     0.560456         9.22229       7.73611 \n",
       " -0.0265723    -0.00562135   -0.249131        -1.13324      -0.23549 \n",
       " -0.015445     -0.00297437   -0.0774922       -0.700187     -0.517042\n",
       " -0.00266711   -0.000667378  -0.00428275   …  -0.0719805    -0.525727\n",
       " -0.0240286    -0.00422512   -0.136925        -0.996459     -0.505827\n",
       " -0.0227289    -0.00636222   -0.114121        -1.12376      -0.509073\n",
       " -0.00949364   -0.00271544   -0.0737856       -0.498747     -0.520085\n",
       "  0.184052      0.0497804     0.420477         5.47025       8.74033 )"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [1.0  0.1  0.2  -0.5  6.1  0.1  0.3  0.1  0.1];\n",
    "LL, LLs, LLgrad, LLgrads = values_test(vec(X), ratdata, 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1556.1926999579518,[-1.40052,-0.226774,-0.122543,-2.15979,-0.162377,-1.53157,-0.0682467,-0.0868616,-0.99925,-0.171958  …  -0.100019,-0.0807075,-1.80416,-0.441352,-0.128942,-0.148185,-0.158402,-0.234555,-0.132733,-1.87679],[-5.341186765092285,-1.8385211882517973,-11.546263650614423,2.8436261876711515,-0.0,-0.0,97.8430805583469,-1047.0994140787998,-431.3758480572178],\n",
       "3000x9 Array{Float64,2}:\n",
       "  0.0288724    0.00865735    0.0405301   …  -0.662526     4.60324    1.15578 \n",
       " -0.00855686  -0.00284973   -0.012017        0.0368794   -1.69031   -0.418795\n",
       " -0.0062268   -0.00205026   -0.0136494       0.137573    -1.3617    -0.488557\n",
       "  0.0494535    0.0152037     0.185694       -0.558722     7.96629    3.74681 \n",
       " -0.00703888  -0.00244581   -0.03096         0.00304722  -1.09416   -0.462751\n",
       "  0.0350891    0.0100739     0.0768755   …  -0.116364     1.86913    1.47495 \n",
       " -0.00216419  -0.000729293  -0.00186401      0.0300186   -0.324013  -0.522118\n",
       " -0.00478068  -0.00133116   -0.00375675      0.0565271   -0.715143  -0.510817\n",
       "  0.0105894    0.00344161    0.0466147      -0.146008     2.74704    0.402385\n",
       " -0.00803825  -0.00260766   -0.00835883      0.169659    -2.02376   -0.456389\n",
       "  0.0106036    0.00283562    0.0262291   …  -0.073158     0.381899   0.329237\n",
       " -0.00359839  -0.00143754   -0.00456068      0.0792024   -0.73597   -0.509749\n",
       " -0.00765842  -0.00275585   -0.0401064       0.0300749   -0.650133  -0.371469\n",
       "  ⋮                                      ⋱                                   \n",
       "  0.0199694    0.00660514    0.0879437      -0.813852     6.42038    0.844924\n",
       "  0.0549001    0.0155347     0.0571088      -0.513703     6.78611    3.61172 \n",
       " -0.00428303  -0.00169988   -0.00834479  …   0.0259263   -0.667837  -0.502701\n",
       " -0.00315907  -0.00118744   -0.0061553       0.0514357   -0.584337  -0.514577\n",
       "  0.0334682    0.0139377     0.0348231      -0.872401     7.61012    2.28924 \n",
       " -0.00642609  -0.00200106   -0.051203        0.35072     -0.457311  -0.250108\n",
       " -0.00753988  -0.00201526   -0.0282809       0.100047    -1.21507   -0.484481\n",
       " -0.00661364  -0.00245468   -0.00474705  …   0.145195    -1.26954   -0.472063\n",
       " -0.00945304  -0.00223316   -0.0415698       0.0505008   -1.1147    -0.465372\n",
       " -0.00688328  -0.0028727    -0.0258257       0.144167    -2.21044   -0.413288\n",
       " -0.00501492  -0.00217495   -0.0319096       0.0896822   -1.07938   -0.482053\n",
       "  0.0369367    0.0145011     0.0468111      -0.167355     5.41285    2.54637 )"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_m = [-1.87  1.38    40.6    0.2       7   0.351  0.067   0.25   0.11]\n",
    "idx_chg = [2,3,4,1,5,8,6,7,9];\n",
    "LL, LLs, LLgrad, LLgrads = values_test(vec(X_m[idx_chg]), ratdata, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " 0.0966105\n",
       " 0.940053 \n",
       " 0.948477 \n",
       " 0.0579302\n",
       " 0.932401 \n",
       " 0.10389  \n",
       " 0.949998 \n",
       " 0.949973 \n",
       " 0.250868 \n",
       " 0.943912 "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp(LLs[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X = [2.0277     1.1740    1.1142    -0.6808   5.3390    0.7396    1.5260    0.5899    0.1689];\n",
    "X = [-0.0078    0.4259   16.9251    7.9173   19.3745    0.8666    0.6998    0.4854    0.0475];\n",
    "idx_chg = [2,3,4,1,5,8,6,7,9];\n",
    "\n",
    "LL, LLs, LLgrad, LLgrads = values_test(vec(X[idx_chg]), ratdata, 9342)\n",
    "\n",
    "println(\"LL : \", LL, \", LL_grad : \", -LLgrad[idx_9p_jtom])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.8697321971645661 3.267542982007349 0.8813023894599701 5.232167132450805 0.0 -52.840647449394105 405.6977821036609 61.010338760419685 174.9258705435296]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.8013559761211032 3.2804566078951525 0.8827473385814747 5.620278464280778 0.0 -52.840159601343466 407.7046807060147 60.587788226345005 175.6943005071867]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.7316044024306101 3.289560039402798 0.883195190508405 6.0143370127031925 0.0 -52.78300097781783 409.4283490735966 60.14903492103904 176.2305325423956]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.6611492529692296 3.2948915205409905 0.882652650548601 6.413216014638021 0.0 -52.68702267295432 410.7851428716711 59.69396894539533 176.53432421359156]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.5911156547822454 3.296572595095594 0.8811320268377651 6.8157490750315075 0.0 -52.50658084014538 411.46849264467824 59.22368497541364 176.60754090397575]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.5040931531721085 3.2931471161873374 0.8785157384412209 7.218519636819485 0.0 -52.27894465842535 411.75997528684366 58.74050992845017 176.42433780157992]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.4294206900823473 3.28581598816911 0.8748763907899735 7.621059549071239 0.0 -51.85688650446015 411.00589496138156 58.24529662444072 175.9990642686351]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.35454489874232187 3.2746270371186093 0.8702488788125192 8.022019581366056 0.0 -51.51055825588658 410.7395792160324 57.738400251907905 175.33493526738621]\n",
      "     sum_ll_all_trials: running trial 1000/3000\n",
      "     sum_ll_all_trials: running trial 2000/3000\n",
      "     sum_ll_all_trials: running trial 3000/3000\n",
      "[-0.28228241029727474 3.259374280818211 0.8646223257812 8.419661468240044 0.0 -51.115889732042014 409.6816186454098 57.22088823675575 174.4300779318356]\n"
     ]
    }
   ],
   "source": [
    "lam_cand = -0.5:0.12:0.5;\n",
    "X_orig = [1.0  40.0  0.2 -0.5  7  0.1  0.3  0.1  0.1];\n",
    "\n",
    "GRs_j = zeros(length(lam_cand),9)\n",
    "for i=1:length(lam_cand)\n",
    "    X = vec(X_orig);\n",
    "    X[4] = lam_cand[i]\n",
    "    \n",
    "    LL,LLgrad = SumLikey(X, ratdata, 3000);\n",
    "    GRs_j[i,:] = -LLgrad[idx_9p_jtom];\n",
    "    println(-LLgrad[idx_9p_jtom])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(-LLgrad[idx_9p_jtom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LLs[1:20]\n",
    "# LLs[21:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matwrite(\"GRs_j.mat\",Dict([(\"GRs_j\",GRs_j),]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9x9 Array{Float64,2}:\n",
       " -0.869732  3.26754  0.881302  …  -52.8406  405.698  61.0103  174.926\n",
       " -0.801356  3.28046  0.882747     -52.8402  407.705  60.5878  175.694\n",
       " -0.731604  3.28956  0.883195     -52.783   409.428  60.149   176.231\n",
       " -0.661149  3.29489  0.882653     -52.687   410.785  59.694   176.534\n",
       " -0.591116  3.29657  0.881132     -52.5066  411.468  59.2237  176.608\n",
       " -0.504093  3.29315  0.878516  …  -52.2789  411.76   58.7405  176.424\n",
       " -0.429421  3.28582  0.874876     -51.8569  411.006  58.2453  175.999\n",
       " -0.354545  3.27463  0.870249     -51.5106  410.74   57.7384  175.335\n",
       " -0.282282  3.25937  0.864622     -51.1159  409.682  57.2209  174.43 "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRs_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time SumLikey_LL(params, ratdata, 30000) # sum of LL for trial (1-27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time SumLikey(params, ratdata, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function Likely_all_trials{T}(LL::AbstractArray{T,1},params::Vector, ratdata, ntrials::Int)     \n",
    "    for i in 1:ntrials\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LL[i] = logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrials = 27\n",
    "likely_all = zeros(ntrials)\n",
    "@time Likely_all_trials(likely_all, params, ratdata, ntrials)\n",
    "likely_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 6.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "\n",
    "ntrials = 300\n",
    "\n",
    "l = [0,   0,    0, -5,  5, -5, 0.01, 0.005, 0]\n",
    "u = [200, 200, 30, +5, 25, +5, 1.2,  0.7,   1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function LL_f(params::Vector)\n",
    "    return SumLikey_LL(params, ratdata, ntrials)\n",
    "end\n",
    "\n",
    "function LL_g!(params::Vector, grads::Vector)\n",
    "#     LL, LLgrad, LLhess = llikey(params)\n",
    "    LL, LLgrad = SumLikey(params, ratdata, ntrials)\n",
    "    for i=1:length(params)\n",
    "        grads[i] = LLgrad[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "function LL_fg!(params::Vector, grads)\n",
    "    LL, LLgrad = SumLikey(params, ratdata, ntrials)\n",
    "    for i=1:length(params)\n",
    "        grads[i] = LLgrad[i]\n",
    "    end\n",
    "    return LL\n",
    "end\n",
    "\n",
    "function LL_h!(params::Vector, hess)\n",
    "    LL, LLhess = SumLikey_hess(params, ratdata, ntrials)\n",
    "    for i=1:length(params)\n",
    "        for j=1:length(params)\n",
    "            hess[i,j] = LLhess[i,j]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "d4 = OnceDifferentiable(LL_f,\n",
    "                            LL_g!,\n",
    "                            LL_fg!)\n",
    "\n",
    "d = TwiceDifferentiableFunction(LL_f, LL_g!, LL_h!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 6.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "\n",
    "params = [-0.0078, 0.4259, 16.9251, 7.9173, 19.3745, 0.8666, 0.6998, 0.4854, 0.0475];\n",
    "params = [-0.6808,    2.0277,    1.1740, 1.1142,    5.3390,    1.5260,    0.5899,    0.7396,    0.1689]\n",
    "l = [0, 0, 0, -5, 5, -5, 0.01, 0.005, 0]\n",
    "u = [200, 200, 30, +5, 25, +5, 1.2, 0.7, 1]\n",
    "\n",
    "# test with max_iteration = 10 \n",
    "tic()\n",
    "options = Optim.Options(g_tol = 1e-12, iterations = 10, show_every = true, \n",
    "store_trace = true,  extended_trace = true,show_trace = true)\n",
    "res = optimize(d4, params, GradientDescent(), options)\n",
    "println(res)\n",
    "toc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 6.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "\n",
    "l = [0, 0, 0, -5, 5, -5, 0.01, 0.005, 0]\n",
    "u = [200, 200, 30, +5, 25, +5, 1.2, 0.7, 1]\n",
    "\n",
    "# test with max_iteration = 10 \n",
    "tic()\n",
    "res = optimize(d4, params, l, u, Fminbox(); \n",
    "         optimizer = ConjugateGradient, optimizer_o = Optim.Options(g_tol = 1e-12,\n",
    "                                                                        iterations = 10,\n",
    "                                                                        show_every = true,\n",
    "                                                                        store_trace = true,\n",
    "                                                                        extended_trace = true,\n",
    "                                                                        show_trace = true))\n",
    "println(res)\n",
    "toc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function my_line_search!(df, x, s, x_scratch, gr_scratch, lsr, alpha,\n",
    "        mayterminate, c1::Real = 1e-4, rhohi::Real = 0.5, rholo::Real = 0.1, iterations::Integer = 1_000)\n",
    "    initial_alpha = 0.5\n",
    "    LineSearches.bt2!(df, x, s,x_scratch, gr_scratch, lsr, initial_alpha,\n",
    "                      mayterminate, c1, rhohi, rholo, iterations)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 6.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "\n",
    "l = [0, 0, 0, -5, 5, -5, 0.01, 0.005, 0]\n",
    "u = [200, 200, 30, +5, 25, +5, 1.2, 0.7, 1]\n",
    "tic()\n",
    "res = optimize(d4, params, l, u, Fminbox(), optimizer = GradientDescent, linesearch = my_line_search!, \n",
    "                    optimizer_o = Optim.Options(g_tol = 1e-12,\n",
    "                                                                        iterations = 20,\n",
    "                                                                        show_every = true,\n",
    "                                                                        store_trace = true,\n",
    "                                                                        extended_trace = true,\n",
    "                                                                        show_trace = true))\n",
    "println(res)\n",
    "toc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.minimizer# res.minimum -> res.minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = getfield(res.trace[1],:metadata)\n",
    "tt[\"g(x)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = res;\n",
    "println(fieldnames(history.trace[1]))\n",
    "\n",
    "Gs = zeros(length(history.trace),length(params))\n",
    "Xs = zeros(length(history.trace),length(params))\n",
    "fs = zeros(length(history.trace))\n",
    "\n",
    "for i=1:length(history.trace)\n",
    "    tt = getfield(history.trace[i],:metadata)\n",
    "    fs[i] = getfield(history.trace[i],:value)\n",
    "    Gs[i,:] = tt[\"g(x)\"]\n",
    "    Xs[i,:] = tt[\"x\"]\n",
    "end\n",
    "\n",
    "Gs\n",
    "# getfield(history.trace[1],4)\n",
    "matwrite(\"res_test.mat\", Dict([(\"f\",history.minimum), \n",
    "                                    (\"x_converged\",history.x_converged),\n",
    "                                    (\"f_converged\",history.f_converged),\n",
    "                                    (\"g_converged\",history.g_converged),\n",
    "                                    (\"x_bf\",history.minimizer),\n",
    "                                    (\"grad_trace\",Gs),\n",
    "                                    (\"f_trace\",fs),\n",
    "                                    (\"x_trace\",Xs),\n",
    "                                    (\"myfval\", history.minimum)\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = optimize(DifferentiableFunction(LL_f), params, l, u, autodiff=true, Fminbox(); \n",
    "optimizer = GradientDescent, optimizer_o = OptimizationOptions(g_tol = 1e-12,\n",
    "                                                                        iterations = 10,\n",
    "                                                                        show_every = true,\n",
    "                                                                        store_trace = true,\n",
    "                                                                        extended_trace = true,\n",
    "                                                                        show_trace = true))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import LineSearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function LL_h!(params::Vector, grads::Vector)\n",
    "# #     LL, LLgrad, LLhess = llikey(params)\n",
    "#     LL, LLgrad = SumLikey(params, ratdata, ntrials)\n",
    "#     for i=1:length(params)\n",
    "#         grads[i] = LLgrad[i]\n",
    "#     end\n",
    "# end\n",
    "\n",
    "results = Optim.optimize(d, params, NewtonTrustRegion(), Optim.Options(g_tol = 1e-12,\n",
    "                                                                      iterations = 200,\n",
    "                                                                      show_every = true,\n",
    "                                                                      store_trace = true,\n",
    "                                                                      extended_trace = true,\n",
    "                                                                      show_trace = true))\n",
    "\n",
    "\n",
    "# algo_mt = Newton(;linesearch = LineSearches.morethuente!)\n",
    "# results_mt = Optim.optimize(d, params, method=algo_mt)\n",
    "\n",
    "# options = OptimizationOptions(show_trace = true, iterations = 10)\n",
    "# Optim.optimize(d4, params, AcceleratedGradientDescent(), options)\n",
    "\n",
    "# Optim.optimize(DifferentiableFunction(LL_f, LL_g!), params, Newton(), OptimizationOptions(autodiff = true))\n",
    "\n",
    "# results = Optim.optimize(d4, params, Newton())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getfield(results.trace[end],:value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# include(\"AutodiffModule.jl\")\n",
    "# import AutodiffModule\n",
    "# using MAT\n",
    "# using Optim\n",
    "\n",
    "function main()\n",
    "\n",
    "    server = 0\n",
    "    if server > 0 \n",
    "        ratname = readline(STDIN) #<- $echo $ratname | julia t3.jl  #\"B069\"\n",
    "        ratname = ratname[1:end-1] \n",
    "    else\n",
    "        ratname = \"B069\"\n",
    "    end\n",
    "    \n",
    "    # data import\n",
    "    if server > 0 \n",
    "        mpath = \"/mnt/bucket/people/amyoon/Data/PBupsModel_rawdata/\"\n",
    "    else\n",
    "        mpath = \"./\"\n",
    "    end\n",
    "    ratdata = matread(*(mpath,\"chrono_\",ratname,\"_rawdata.mat\"))\n",
    "\n",
    "    println(\"rawdata of \", ratname, \" imported\" )\n",
    "\n",
    "    saveto_filename = *(\"julia_out_\",ratname,\".mat\")\n",
    "\n",
    "    # number of trials\n",
    "    ntrials = Int(ratdata[\"total_trials\"])\n",
    "\n",
    "    # Parameters\n",
    "    sigma_a = rand()*4.; sigma_s = rand()*4.; sigma_i = rand()*30.; \n",
    "    lam = randn(); B = rand()*20.+5.; bias = randn(); \n",
    "    phi = rand()*1.19+0.01; tau_phi = 0.695*rand()+0.005; lapse = rand();\n",
    "\n",
    "    # sigma_a = 1.; sigma_s = 0.1; sigma_i = 0.2; \n",
    "    # lam = -0.0005; B = 6.1; bias = 0.1; \n",
    "    # phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "    params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "\n",
    "    l = [0.,   0.,   0., -5., 5., -5., 0.01, 0.005, 0.]\n",
    "    u = [200., 200., 30., 5., 25., 5., 1.2,  0.7,   1.]\n",
    "\n",
    "    # @code_warntype SumLikey(params, ratdata, ntrials)\n",
    "\n",
    "    function LL_f(params::Vector)\n",
    "        return AutodiffModule.SumLikey_LL(params, ratdata, ntrials)\n",
    "    end\n",
    "\n",
    "    function LL_g!(params::Vector, grads::Vector)\n",
    "#         LL, LLgrad = AutodiffModule.SumLikey(params, ratdata, ntrials)\n",
    "        LL, LLgrad = SumLikey(params, ratdata, ntrials)        \n",
    "        for i=1:length(params)\n",
    "            grads[i] = LLgrad[i]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function LL_fg!(params::Vector, grads)\n",
    "#         LL, LLgrad = AutodiffModule.SumLikey(params, ratdata, ntrials)\n",
    "        LL, LLgrad = SumLikey(params, ratdata, ntrials)\n",
    "        for i=1:length(params)\n",
    "            grads[i] = LLgrad[i]\n",
    "        end\n",
    "        return LL\n",
    "    end\n",
    "\n",
    "    d4 = DifferentiableFunction(LL_f,\n",
    "                                LL_g!,\n",
    "                                LL_fg!)\n",
    "\n",
    "    tic()\n",
    "    history = optimize(d4, params, l, u, Fminbox(); \n",
    "             optimizer = GradientDescent, optimizer_o = OptimizationOptions(g_tol = 1e-12,\n",
    "                                                                            x_tol = 1e-10,\n",
    "                                                                            f_tol = 1e-6,\n",
    "                                                                            iterations = 200,\n",
    "                                                                            store_trace = true,\n",
    "                                                                            ))\n",
    "    fit_time = toc()\n",
    "    println(history.minimum)\n",
    "    println(history)\n",
    "\n",
    "    ## do a single functional evaluation at best fit parameters and save likely for each trial\n",
    "    likely_all = zeros(typeof(sigma_i),ntrials)\n",
    "    x_bf = history.minimum\n",
    "    Likely_all_trials(likely_all, x_bf, ratdata, ntrials)\n",
    "\n",
    "    matwrite(saveto_filename, Dict([(\"ratname\",ratname),\n",
    "                                    (\"x_init\",params),\n",
    "                                    (\"trials\",ntrials),\n",
    "                                    (\"history\",history),\n",
    "                                    (\"f\",history.f_minimum), \n",
    "                                    (\"x_converged\",history.x_converged),\n",
    "                                    (\"f_converged\",history.f_converged),\n",
    "                                    (\"g_converged\",history.g_converged),                                    \n",
    "                                    (\"fit_time\",fit_time),\n",
    "                                    (\"x_bf\",history.minimum),\n",
    "                                    (\"myfval\", history.f_minimum),\n",
    "                                    (\"likely\",likely_all)\n",
    "                                    ]))\n",
    "     # hessian?\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0:dx:ceil(4.1/0.25)*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = -floor(4.1/0.25)*dx:dx:floor(4.1/0.25)*dx\n",
    "collect(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[-aa[end:-1:1]; aa]\n",
    "[-aa; aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqrt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using LineSearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# d4 = DifferentiableFunction(LL_f,\n",
    "#                             LL_g!,\n",
    "#                             LL_fg!)\n",
    "\n",
    "# d = TwiceDifferentiableFunction(LL_f, LL_g!, LL_h!)\n",
    "\n",
    "\n",
    "algo_mt = Newton(;linesearch = LineSearches.morethuente!)\n",
    "results_mt = Optim.optimize(LL_f, LL_g!, LL_h!, params, method=algo_mt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo_hz = NewtonTrustRegion(;linesearch = LineSearches.hagerzhang!)\n",
    "results_hz = Optim.optimize(LL_f, LL_g!, LL_h!, params, method=algo_hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo_grad = GradientDescent(; linesearch = LineSearches.morethuente!,\n",
    "                  P = nothing,\n",
    "                  precondprep = (P, x) -> nothing)\n",
    "results_gd = Optim.optimize(LL_f, LL_g!, LL_h!, params, method=algo_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = [0, 0, 0, -5, 5, -5, 0.01, 0.005, 0]\n",
    "u = [200, 200, 30, +5, 25, +5, 1.2, 0.7, 1]\n",
    "\n",
    "# test with max_iteration = 10 \n",
    "res = optimize(d4, params, l, u, Fminbox(); \n",
    "         optimizer = algo_grad, optimizer_o = Optim.Options(g_tol = 1e-12,\n",
    "                                                                        iterations = 10,\n",
    "                                                                        show_every = true,\n",
    "                                                                        store_trace = true,\n",
    "                                                                        extended_trace = true,\n",
    "                                                                        show_trace = true))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo_lbfgs = LBFGS(;m = 10,\n",
    "        linesearch = LineSearches.hagerzhang!,\n",
    "                  P = nothing,\n",
    "                  precondprep = (P, x) -> nothing)\n",
    "results_gd = Optim.optimize(LL_f, LL_g!, LL_h!, params, method=algo_lbfgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# results_gd = Optim.optimize(LL_f, LL_g!, LL_h!, params, method=algo_grad)\n",
    "res = optimize(d4, params, l, u, Fminbox(); \n",
    "optimizer = GradientDescent, show_trace = true, mu0 = 0.2, optimizer_o = Optim.Options(g_tol = 1e-12,\n",
    "                                                                        iterations = 10,\n",
    "                                                                        show_every = true,\n",
    "                                                                        store_trace = true,\n",
    "                                                                        extended_trace = true,\n",
    "                                                                        show_trace = true))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduced model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = [\"a\",\"bd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"a\",\"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratdata[\"rawdata\"][\"leftbups\"][randperm(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrials = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratdata[\"rawdata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bid = randperm(ntrials);\n",
    "ratdata[\"rawdata\"][\"leftbups\"] = ratdata[\"rawdata\"][\"leftbups\"][bid];\n",
    "ratdata[\"rawdata\"][\"rightbups\"] = ratdata[\"rawdata\"][\"rightbups\"][bid];\n",
    "ratdata[\"rawdata\"][\"T\"] = ratdata[\"rawdata\"][\"T\"][bid];\n",
    "ratdata[\"rawdata\"][\"pokedR\"] = ratdata[\"rawdata\"][\"pokedR\"][bid];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratdata[\"rawdata\"][\"rightbups\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using MAT\n",
    "\n",
    "matwrite(\"test.mat\",Dict(\n",
    "        \"var1\" => 0,\n",
    "        \"var2\" => 1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{ByteString,Any} with 2 entries:\n",
       "  \"myvar1\" => 0\n",
       "  \"myvar2\" => 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matread(\"test.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
